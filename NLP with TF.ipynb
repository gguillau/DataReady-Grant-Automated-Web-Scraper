{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('grantGov_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Opportunity Number</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Agency Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Transitions to Excellence in Molecular and Cel...</td>\n",
       "      <td>21-508</td>\n",
       "      <td>Unrestricted (i.e., open to any type of entity...</td>\n",
       "      <td>National Science Foundation</td>\n",
       "      <td>The Division of Molecular and Cellular Bioscie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Plant Genome Research Program</td>\n",
       "      <td>21-507</td>\n",
       "      <td>Unrestricted (i.e., open to any type of entity...</td>\n",
       "      <td>National Science Foundation</td>\n",
       "      <td>\\n\\n\\n\\nThe Plant Genome Research Program (PGR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Division of Integrative Organismal Systems Cor...</td>\n",
       "      <td>21-506</td>\n",
       "      <td>Unrestricted (i.e., open to any type of entity...</td>\n",
       "      <td>National Science Foundation</td>\n",
       "      <td>\\n\\nThe Division of Integrative Organismal Sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Algebra and Number Theory</td>\n",
       "      <td>PD-20-1264</td>\n",
       "      <td>Unrestricted (i.e., open to any type of entity...</td>\n",
       "      <td>National Science Foundation</td>\n",
       "      <td>The Algebra and Number Theory program supports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Successor-in-Interest (Type 6 Parent Clinical ...</td>\n",
       "      <td>PA-20-275</td>\n",
       "      <td>Public housing authorities/Indian housing auth...</td>\n",
       "      <td>National Institutes of Health</td>\n",
       "      <td>The National Institutes of Health (NIH) hereby...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Name  \\\n",
       "0           0  Transitions to Excellence in Molecular and Cel...   \n",
       "1           1                      Plant Genome Research Program   \n",
       "2           2  Division of Integrative Organismal Systems Cor...   \n",
       "3           3                          Algebra and Number Theory   \n",
       "4           4  Successor-in-Interest (Type 6 Parent Clinical ...   \n",
       "\n",
       "  Opportunity Number                                        Eligibility  \\\n",
       "0             21-508  Unrestricted (i.e., open to any type of entity...   \n",
       "1             21-507  Unrestricted (i.e., open to any type of entity...   \n",
       "2             21-506  Unrestricted (i.e., open to any type of entity...   \n",
       "3         PD-20-1264  Unrestricted (i.e., open to any type of entity...   \n",
       "4          PA-20-275  Public housing authorities/Indian housing auth...   \n",
       "\n",
       "                     Agency Name  \\\n",
       "0    National Science Foundation   \n",
       "1    National Science Foundation   \n",
       "2    National Science Foundation   \n",
       "3    National Science Foundation   \n",
       "4  National Institutes of Health   \n",
       "\n",
       "                                         Description  \n",
       "0  The Division of Molecular and Cellular Bioscie...  \n",
       "1  \\n\\n\\n\\nThe Plant Genome Research Program (PGR...  \n",
       "2  \\n\\nThe Division of Integrative Organismal Sys...  \n",
       "3  The Algebra and Number Theory program supports...  \n",
       "4  The National Institutes of Health (NIH) hereby...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicable grant index:\n",
    "31, 51, 75, 160, 184, 216, 271, 330, 355, 388, 395, 531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [31, 51, 75, 160, 184, 216, 271, 330, 355, 388, 395, 531] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredTest = []\n",
    "[filteredTest.append(data.loc[x]) for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDf = data.loc[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = filteredDf['Description'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF selecting keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF (Term frequency inverse document frequency): \n",
    "* https://en.wikipedia.org/wiki/Tf–idf \n",
    "* TF_IDF(w,d,D) = Term_frequency(w,d) * Inverse_document_frequency(w,D)\n",
    "    * w = word (term)\n",
    "    * d = document\n",
    "    * D = set of all documents\n",
    "    * Term_frequency(w,d) = d.count(w)\n",
    "    * Inverse_document_frequency(w,D) = log(|D|/|docs containing w|)\n",
    "    \n",
    "    \n",
    "### TextBlob\n",
    "* https://pythonprogramming.net/part-of-speech-tagging-nltk-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRANTS.GOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "texts = [x.replace('\\n', ' ') for x in texts]\n",
    "texts = [x.replace(\"’\", ' ') for x in texts]\n",
    "\n",
    "# Remove punctuation\n",
    "texts = [''.join(c for c in x if c not in string.punctuation) for x in texts]\n",
    "# Remove numbers\n",
    "texts = [''.join(c for c in x if c not in '0123456789') for x in texts]\n",
    "# clean out capitalization\n",
    "texts = [txt.lower() for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make bag of words\n",
    "# blob = [txt.split() for txt in texts]\n",
    "\n",
    "# Use TextBlob\n",
    "# TFIDF with textblob: https://gist.github.com/sloria/6407257\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "bloblist = [tb(x) for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('advancing', 'VBG'),\n",
       " ('informal', 'JJ'),\n",
       " ('stem', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('aisl', 'JJ')]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first few tags\n",
    "bloblist[0].tags[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "Word: aisl, TF-IDF: 0.03772\n",
      "Word: informal, TF-IDF: 0.03686\n",
      "Word: learning, TF-IDF: 0.02269\n",
      "Word: evidencebased, TF-IDF: 0.01886\n",
      "Word: learningopportunities, TF-IDF: 0.01886\n",
      "Word: forthe, TF-IDF: 0.01886\n",
      "Word: assessment, TF-IDF: 0.01886\n",
      "Word: environmentsthe, TF-IDF: 0.01886\n",
      "Word: six, TF-IDF: 0.01886\n",
      "Word: pilots, TF-IDF: 0.01886\n",
      "Word: feasibility, TF-IDF: 0.01886\n",
      "Word: literature, TF-IDF: 0.01886\n",
      "Word: reviews, TF-IDF: 0.01886\n",
      "Word: syntheses, TF-IDF: 0.01886\n",
      "Word: metaanalyses, TF-IDF: 0.01886\n",
      "Word: environments, TF-IDF: 0.01843\n",
      "Word: public, TF-IDF: 0.01459\n",
      "Word: access, TF-IDF: 0.01459\n",
      "Word: engagement, TF-IDF: 0.01459\n",
      "Word: practice, TF-IDF: 0.01459\n",
      "Top words in document 2\n",
      "Word: graduate, TF-IDF: 0.03194\n",
      "Word: ige, TF-IDF: 0.02531\n",
      "Word: hub, TF-IDF: 0.02477\n",
      "Word: implementation, TF-IDF: 0.01917\n",
      "Word: centers, TF-IDF: 0.01651\n",
      "Word: testing, TF-IDF: 0.01278\n",
      "Word: potentially, TF-IDF: 0.01013\n",
      "Word: transformative, TF-IDF: 0.01013\n",
      "Word: knowledge, TF-IDF: 0.00958\n",
      "Word: will, TF-IDF: 0.00958\n",
      "Word: education, TF-IDF: 0.00934\n",
      "Word: bold, TF-IDF: 0.00826\n",
      "Word: explore, TF-IDF: 0.00826\n",
      "Word: forgraduate, TF-IDF: 0.00826\n",
      "Word: researchbased, TF-IDF: 0.00826\n",
      "Word: master, TF-IDF: 0.00826\n",
      "Word: doctoral, TF-IDF: 0.00826\n",
      "Word: degree, TF-IDF: 0.00826\n",
      "Word: competencies, TF-IDF: 0.00826\n",
      "Word: careersige, TF-IDF: 0.00826\n",
      "Top words in document 3\n",
      "Word: cdse, TF-IDF: 0.02502\n",
      "Word: chemical, TF-IDF: 0.01251\n",
      "Word: algorithms, TF-IDF: 0.00938\n",
      "Word: computational, TF-IDF: 0.00806\n",
      "Word: tools, TF-IDF: 0.00806\n",
      "Word: mathematical, TF-IDF: 0.0073\n",
      "Word: mpsdivision, TF-IDF: 0.0073\n",
      "Word: data, TF-IDF: 0.00658\n",
      "Word: core, TF-IDF: 0.00625\n",
      "Word: engineering, TF-IDF: 0.00564\n",
      "Word: modeling, TF-IDF: 0.0056\n",
      "Word: systems, TF-IDF: 0.00524\n",
      "Word: disciplines, TF-IDF: 0.00521\n",
      "Word: large, TF-IDF: 0.00521\n",
      "Word: expected, TF-IDF: 0.00521\n",
      "Word: cyber, TF-IDF: 0.00521\n",
      "Word: advanced, TF-IDF: 0.00484\n",
      "Word: analysis, TF-IDF: 0.00458\n",
      "Word: scientific, TF-IDF: 0.00447\n",
      "Word: phy, TF-IDF: 0.00447\n",
      "Top words in document 4\n",
      "Word: women, TF-IDF: 0.0302\n",
      "Word: empowerment, TF-IDF: 0.02013\n",
      "Word: youth, TF-IDF: 0.02013\n",
      "Word: disinformation, TF-IDF: 0.02013\n",
      "Word: economic, TF-IDF: 0.01852\n",
      "Word: management, TF-IDF: 0.01558\n",
      "Word: chennai, TF-IDF: 0.01007\n",
      "Word: objectives, TF-IDF: 0.01007\n",
      "Word: primarily, TF-IDF: 0.01007\n",
      "Word: areas·, TF-IDF: 0.01007\n",
      "Word: inclusive, TF-IDF: 0.01007\n",
      "Word: growth, TF-IDF: 0.01007\n",
      "Word: india, TF-IDF: 0.01007\n",
      "Word: ecosystem, TF-IDF: 0.01007\n",
      "Word: indian, TF-IDF: 0.01007\n",
      "Word: businesses, TF-IDF: 0.01007\n",
      "Word: undeserved, TF-IDF: 0.01007\n",
      "Word: populations·, TF-IDF: 0.01007\n",
      "Word: countering, TF-IDF: 0.01007\n",
      "Word: reinforce, TF-IDF: 0.01007\n",
      "Top words in document 5\n",
      "Word: schools, TF-IDF: 0.03466\n",
      "Word: aims, TF-IDF: 0.02986\n",
      "Word: preparation, TF-IDF: 0.02986\n",
      "Word: computer, TF-IDF: 0.0231\n",
      "Word: prek, TF-IDF: 0.0231\n",
      "Word: opportunity, TF-IDF: 0.01493\n",
      "Word: participate, TF-IDF: 0.01493\n",
      "Word: researcherpractitioner, TF-IDF: 0.01493\n",
      "Word: rpps, TF-IDF: 0.01493\n",
      "Word: foster, TF-IDF: 0.01493\n",
      "Word: specifically, TF-IDF: 0.01493\n",
      "Word: teacherswith, TF-IDF: 0.01493\n",
      "Word: professional, TF-IDF: 0.01493\n",
      "Word: pd, TF-IDF: 0.01493\n",
      "Word: ongoing, TF-IDF: 0.01493\n",
      "Word: courses, TF-IDF: 0.01493\n",
      "Word: districtswith, TF-IDF: 0.01493\n",
      "Word: define, TF-IDF: 0.01493\n",
      "Word: multigrade, TF-IDF: 0.01493\n",
      "Word: solicitation, TF-IDF: 0.01459\n",
      "Top words in document 6\n",
      "Word: intelligence, TF-IDF: 0.02616\n",
      "Word: learning, TF-IDF: 0.01664\n",
      "Word: augmented, TF-IDF: 0.01537\n",
      "Word: processes, TF-IDF: 0.01427\n",
      "Word: artificial, TF-IDF: 0.01427\n",
      "Word: from, TF-IDF: 0.01319\n",
      "Word: how, TF-IDF: 0.01201\n",
      "Word: what, TF-IDF: 0.01189\n",
      "Word: human, TF-IDF: 0.01131\n",
      "Word: cognitive, TF-IDF: 0.00922\n",
      "Word: brain, TF-IDF: 0.00922\n",
      "Word: improved, TF-IDF: 0.00922\n",
      "Word: biological, TF-IDF: 0.00922\n",
      "Word: mechanisms, TF-IDF: 0.00754\n",
      "Word: can, TF-IDF: 0.0074\n",
      "Word: insights, TF-IDF: 0.00713\n",
      "Word: interactions, TF-IDF: 0.00713\n",
      "Word: collaborative, TF-IDF: 0.00713\n",
      "Word: affective, TF-IDF: 0.00615\n",
      "Word: behavioral, TF-IDF: 0.00615\n",
      "Top words in document 7\n",
      "Word: itest, TF-IDF: 0.05292\n",
      "Word: occupations, TF-IDF: 0.01512\n",
      "Word: practices, TF-IDF: 0.01512\n",
      "Word: highquality, TF-IDF: 0.01512\n",
      "Word: workforce, TF-IDF: 0.01391\n",
      "Word: innovative, TF-IDF: 0.0117\n",
      "Word: pursue, TF-IDF: 0.0117\n",
      "Word: strategic, TF-IDF: 0.0117\n",
      "Word: which, TF-IDF: 0.0117\n",
      "Word: ict, TF-IDF: 0.01108\n",
      "Word: students, TF-IDF: 0.01108\n",
      "Word: innovations, TF-IDF: 0.01108\n",
      "Word: those, TF-IDF: 0.00927\n",
      "Word: learning, TF-IDF: 0.0091\n",
      "Word: technology, TF-IDF: 0.00877\n",
      "Word: prekindergarten, TF-IDF: 0.00756\n",
      "Word: strengthen, TF-IDF: 0.00756\n",
      "Word: purpose, TF-IDF: 0.00756\n",
      "Word: technologyrich, TF-IDF: 0.00756\n",
      "Word: awareness, TF-IDF: 0.00756\n",
      "Top words in document 8\n",
      "Word: sharing, TF-IDF: 0.05688\n",
      "Word: library, TF-IDF: 0.02844\n",
      "Word: medicine, TF-IDF: 0.02844\n",
      "Word: informatics, TF-IDF: 0.02844\n",
      "Word: gather, TF-IDF: 0.02844\n",
      "Word: personal, TF-IDF: 0.02844\n",
      "Word: patients, TF-IDF: 0.02844\n",
      "Word: results, TF-IDF: 0.02844\n",
      "Word: open, TF-IDF: 0.02844\n",
      "Word: data, TF-IDF: 0.02567\n",
      "Word: help, TF-IDF: 0.022\n",
      "Word: health, TF-IDF: 0.022\n",
      "Word: via, TF-IDF: 0.022\n",
      "Word: publication, TF-IDF: 0.022\n",
      "Word: novel, TF-IDF: 0.01744\n",
      "Word: individuals, TF-IDF: 0.01744\n",
      "Word: manage, TF-IDF: 0.01744\n",
      "Word: broadly, TF-IDF: 0.01744\n",
      "Word: mechanisms, TF-IDF: 0.01744\n",
      "Word: applications, TF-IDF: 0.0139\n",
      "Top words in document 9\n",
      "Word: xc, TF-IDF: 0.04429\n",
      "Word: dmr, TF-IDF: 0.01558\n",
      "Word: materials, TF-IDF: 0.01453\n",
      "Word: international, TF-IDF: 0.01208\n",
      "Word: handled, TF-IDF: 0.01208\n",
      "Word: original, TF-IDF: 0.01208\n",
      "Word: activities, TF-IDF: 0.0118\n",
      "Word: award, TF-IDF: 0.00988\n",
      "Word: crosscutting, TF-IDF: 0.00935\n",
      "Word: programs, TF-IDF: 0.00935\n",
      "Word: institutes, TF-IDF: 0.00805\n",
      "Word: policies, TF-IDF: 0.00805\n",
      "Word: procedures, TF-IDF: 0.00805\n",
      "Word: cofunded, TF-IDF: 0.00805\n",
      "Word: elsewhere, TF-IDF: 0.00805\n",
      "Word: reu, TF-IDF: 0.00805\n",
      "Word: within, TF-IDF: 0.00787\n",
      "Word: division, TF-IDF: 0.00623\n",
      "Word: diversity, TF-IDF: 0.00623\n",
      "Word: inclusion, TF-IDF: 0.00623\n",
      "Top words in document 10\n",
      "Word: operations, TF-IDF: 0.02683\n",
      "Word: analytical, TF-IDF: 0.02312\n",
      "Word: methodological, TF-IDF: 0.02312\n",
      "Word: motivated, TF-IDF: 0.02312\n",
      "Word: problems, TF-IDF: 0.01418\n",
      "Word: decisiondriven, TF-IDF: 0.01156\n",
      "Word: deterministic, TF-IDF: 0.01156\n",
      "Word: stochastic, TF-IDF: 0.01156\n",
      "Word: arise, TF-IDF: 0.01156\n",
      "Word: commercial, TF-IDF: 0.01156\n",
      "Word: enterprises, TF-IDF: 0.01156\n",
      "Word: productionmanufacturing, TF-IDF: 0.01156\n",
      "Word: distribution, TF-IDF: 0.01156\n",
      "Word: delivery, TF-IDF: 0.01156\n",
      "Word: sectorgovernment, TF-IDF: 0.01156\n",
      "Word: safety, TF-IDF: 0.01156\n",
      "Word: security, TF-IDF: 0.01156\n",
      "Word: publicprivate, TF-IDF: 0.01156\n",
      "Word: systemic, TF-IDF: 0.01156\n",
      "Word: applicationspecific, TF-IDF: 0.01156\n",
      "Top words in document 11\n",
      "Word: infrastructure, TF-IDF: 0.03266\n",
      "Word: natural, TF-IDF: 0.02177\n",
      "Word: civil, TF-IDF: 0.01726\n",
      "Word: structural, TF-IDF: 0.01407\n",
      "Word: investigators, TF-IDF: 0.01407\n",
      "Word: nheri, TF-IDF: 0.01407\n",
      "Word: hazards, TF-IDF: 0.01089\n",
      "Word: architectural, TF-IDF: 0.00938\n",
      "Word: conditions, TF-IDF: 0.00938\n",
      "Word: loading, TF-IDF: 0.00938\n",
      "Word: reduction, TF-IDF: 0.00938\n",
      "Word: characterization, TF-IDF: 0.00938\n",
      "Word: encouraged, TF-IDF: 0.00917\n",
      "Word: such, TF-IDF: 0.00863\n",
      "Word: environmental, TF-IDF: 0.00726\n",
      "Word: hazard, TF-IDF: 0.00726\n",
      "Word: resources, TF-IDF: 0.00575\n",
      "Word: does, TF-IDF: 0.00575\n",
      "Word: geotechnical, TF-IDF: 0.00469\n",
      "Word: shape, TF-IDF: 0.00469\n",
      "Top words in document 12\n",
      "Word: soo, TF-IDF: 0.03059\n",
      "Word: organizational, TF-IDF: 0.02185\n",
      "Word: management, TF-IDF: 0.01691\n",
      "Word: limited, TF-IDF: 0.01352\n",
      "Word: effectiveness, TF-IDF: 0.01311\n",
      "Word: organizations, TF-IDF: 0.01068\n",
      "Word: may, TF-IDF: 0.01068\n",
      "Word: funds, TF-IDF: 0.00874\n",
      "Word: generalizable, TF-IDF: 0.00874\n",
      "Word: industrial, TF-IDF: 0.00874\n",
      "Word: change, TF-IDF: 0.00874\n",
      "Word: scientific, TF-IDF: 0.00804\n",
      "Word: value, TF-IDF: 0.00676\n",
      "Word: basic, TF-IDF: 0.00676\n",
      "Word: evidence, TF-IDF: 0.00676\n",
      "Word: methods, TF-IDF: 0.00676\n",
      "Word: theories, TF-IDF: 0.00676\n",
      "Word: business, TF-IDF: 0.00676\n",
      "Word: any, TF-IDF: 0.00676\n",
      "Word: but, TF-IDF: 0.00676\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "wrd = []\n",
    "scr = []\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:20]:\n",
    "        print(\"Word: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "        num.append(i)\n",
    "        wrd.append(word)\n",
    "        scr.append(round(score, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to csv\n",
    "# dictionary of lists   \n",
    "dict = {'Grant#': num, 'Word': wrd, 'TFIDF Score': scr}         \n",
    "df = pd.DataFrame(dict)      \n",
    "# saving the dataframe  \n",
    "df.to_csv('Top20Words.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRANTFWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#McClure, Nick. Tensorflow Machine Learning Cookbook. Packt Publishing, 2017.\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import requests\n",
    "import io\n",
    "import nltk\n",
    "from zipfile import ZipFile\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "batch_size= 200\n",
    "max_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "texts = [x[1] for x in text_data]\n",
    "target = [x[0] for x in text_data]\n",
    "# Relabel 'yes' as 1, 'no' as 0\n",
    "target = [1. if x=='yes' else 0. for x in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean symbols\n",
    "texts = filteredDf['Description'].to_list()\n",
    "texts = [x.replace('\\n', '') for x in texts]\n",
    "# Lower case\n",
    "texts = [x.lower() for x in texts]\n",
    "# Remove punctuation\n",
    "texts = [''.join(c for c in x if c not in string.punctuation) for x in texts]\n",
    "# Remove numbers\n",
    "texts = [''.join(c for c in x if c not in '0123456789') for x in texts]\n",
    "# Trim extra whitespace\n",
    "texts = [' '.join(x.split()) for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words\n",
    "# Create TF-IDF of texts\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, stop_words='english', max_features=max_features)\n",
    "sparse_tfidf_texts = tfidf.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-38e1429434f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtexts_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_tfidf_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtexts_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_tfidf_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtarget_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtarget_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "#break data set in to test and train set\n",
    "#label filtered data TBD\n",
    "train_indices = np.random.choice(sparse_tfidf_texts.shape[0],round(0.8*sparse_tfidf_texts.shape[0]), replace=False)\n",
    "test_indices = np.array(list(set(range(sparse_tfidf_texts.shape[0])) - set(train_indices)))\n",
    "texts_train = sparse_tfidf_texts[train_indices]\n",
    "texts_test = sparse_tfidf_texts[test_indices]\n",
    "target_train = np.array([x for ix, x in enumerate(target) if ix in train_indices])\n",
    "target_test = np.array([x for ix, x in enumerate(target) if ix in test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
